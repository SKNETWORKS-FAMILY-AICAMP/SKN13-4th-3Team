{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1784375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\playdata\\appdata\\local\\miniconda3\\envs\\babsim\\lib\\site-packages (from scikit-learn) (2.3.1)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.7 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 15.8 MB/s eta 0:00:00\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.0-cp313-cp313-win_amd64.whl (38.4 MB)\n",
      "   ---------------------------------------- 0.0/38.4 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 10.2/38.4 MB 49.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.2/38.4 MB 51.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 33.8/38.4 MB 54.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.4/38.4 MB 50.7 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 scipy-1.16.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29735af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jinhy\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1368: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 키워드 후보 리스트\n",
    "REVIEW_KEYWORDS = [\"연비\", \"주행감\", \"실내공간\", \"디자인\", \"하이브리드\", \"정숙성\", \"가속\", \"승차감\", \"가격\", \"안전성\"]\n",
    "DESCRIPTION_KEYWORDS = [\"sleek\", \"modern\", \"aerodynamic\", \"SUV\", \"sedan\", \"electric\", \"hybrid\", \"dynamic\", \"spacious\", \"luxury\"]\n",
    "\n",
    "# 한글 키워드 추출 함수\n",
    "def extract_korean_keywords(text, keyword_list):\n",
    "    return [kw for kw in keyword_list if kw in text]\n",
    "\n",
    "# 영어 키워드 추출 함수\n",
    "def extract_english_keywords(text, keyword_list):\n",
    "    vectorizer = CountVectorizer(vocabulary=keyword_list, lowercase=True)\n",
    "    X = vectorizer.fit_transform([text.lower()])\n",
    "    return [kw for kw, count in zip(vectorizer.get_feature_names_out(), X.toarray()[0]) if count > 0]\n",
    "\n",
    "# assign_metadata 함수\n",
    "def assign_metadata(docs, doc_type='review'):\n",
    "    result = []\n",
    "    for item in docs:\n",
    "        if doc_type == 'review':\n",
    "            car_name_kr = item.get('car_name', '').strip()\n",
    "            car_name_en = car_name_kr.replace(' ', '').replace('하이브리드', 'Hybrid')  # 간단 영문 변환\n",
    "            review_text = item.get('review', '')\n",
    "            review_keywords = extract_korean_keywords(review_text, REVIEW_KEYWORDS)\n",
    "            review_length = len(review_text)\n",
    "            item.update({\n",
    "                'car_name_kr': car_name_kr,\n",
    "                'car_name_en': car_name_en,\n",
    "                'review_keywords': review_keywords,\n",
    "                'review_length': review_length\n",
    "            })\n",
    "        elif doc_type == 'description':\n",
    "            car_name_en = item.get('car_name', '').replace('_', ' ').strip()\n",
    "            car_name_kr = car_name_en.replace('Hybrid', '하이브리드')  # 간단 한글 변환\n",
    "            description_text = item.get('description', '')\n",
    "            description_keywords = extract_english_keywords(description_text, DESCRIPTION_KEYWORDS)\n",
    "            item.update({\n",
    "                'car_name_en': car_name_en,\n",
    "                'car_name_kr': car_name_kr,\n",
    "                'description_keywords': description_keywords\n",
    "            })\n",
    "        result.append(item)\n",
    "    return result\n",
    "\n",
    "# JSON 데이터 로드\n",
    "with open('hyundai_car_reviews.json', 'r', encoding='utf-8') as f:\n",
    "    hyundai_car_reviews = json.load(f)\n",
    "\n",
    "with open('hyundaicar_descript_merge_all.json', 'r', encoding='utf-8') as f:\n",
    "    hyundaicar_descript = json.load(f)\n",
    "\n",
    "# 메타데이터 태깅\n",
    "result_docs = assign_metadata(hyundai_car_reviews, doc_type='review')\n",
    "json_docs = assign_metadata(hyundaicar_descript, doc_type='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24f15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 데이터 로드\n",
    "with open('hyundai_design_philosophy.json', 'r', encoding='utf-8') as f:\n",
    "    hyundai_design_philosophy = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88397e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82cdcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# flatten_tags: tags 딕셔너리를 tags_성능, tags_공간 형태로 평탄화\n",
    "def flatten_tags(tags_dict):\n",
    "    return {f\"tags_{k}\": v for k, v in tags_dict.items()}\n",
    "\n",
    "# 리뷰 Document 생성 (review_keywords 포함)\n",
    "review_documents = [\n",
    "    Document(\n",
    "        page_content=f\"data_id: {item.get('data_id')} | car_name: {item.get('car_name_kr')}, {item.get('car_name_en')}| review: {item.get('review')}\",\n",
    "        metadata={\n",
    "            \"review_length\": item.get('review_length'),\n",
    "            \"review_keywords\": item.get('review_keywords', []),\n",
    "            **flatten_tags(item.get('tags', {}))\n",
    "        }\n",
    "    )\n",
    "    for item in result_docs\n",
    "]\n",
    "\n",
    "# description Document 생성 (description_keywords 포함)\n",
    "description_documents = [\n",
    "    Document(\n",
    "        page_content=f\"car_name: {item.get('car_name_kr')}, {item.get('car_name_en')} | description: {item.get('description')}\",\n",
    "        metadata={\n",
    "            \"description_keywords\": item.get('description_keywords', []),\n",
    "            \"url\": item.get(\"image_path\", [])\n",
    "        }\n",
    "    )\n",
    "    for item in json_docs\n",
    "]\n",
    "\n",
    "philosophy_documents = [\n",
    "    Document(\n",
    "        page_content=item['content'],\n",
    "        metadata={\n",
    "            \"id\": item.get('id'),\n",
    "            \"source_document\": item.get(\"source_document\")\n",
    "        }\n",
    "    )\n",
    "    for item in hyundai_design_philosophy\n",
    "]\n",
    "\n",
    "total_documents = philosophy_documents + review_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7169cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca274439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 881건의 청크된 문서 생성 완료\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30\n",
    ")\n",
    "split_docs_1 = text_splitter.split_documents(total_documents)\n",
    "print(f\"✅ 총 {len(split_docs_1)}건의 청크된 문서 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af8c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 139건의 청크된 문서 생성 완료\n"
     ]
    }
   ],
   "source": [
    "split_docs_2 = text_splitter.split_documents(description_documents)\n",
    "print(f\"✅ 총 {len(split_docs_2)}건의 청크된 문서 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a31c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinhy\\AppData\\Local\\Temp\\ipykernel_15148\\345430399.py:14: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ description_vector_store 컬렉션 생성 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinhy\\AppData\\Local\\Temp\\ipykernel_15148\\345430399.py:24: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ feedback_vector_store 컬렉션 생성 완료\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "import os\n",
    "\n",
    "QDRANT_PATH = \"./Qdrant_DB\"\n",
    "EMBEDDING_DIM = 3072\n",
    "HOST = os.getenv(\"HOST_PUBLIC_IP\")\n",
    "\n",
    "client = QdrantClient(host=HOST, port=6333)\n",
    "\n",
    "# description용 컬렉션 생성\n",
    "client.recreate_collection(\n",
    "    collection_name=\"description_vector_store\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=EMBEDDING_DIM,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(\"✅ description_vector_store 컬렉션 생성 완료\")\n",
    "\n",
    "# review용 컬렉션 생성 (예: 임베딩 차원이 다르면 size 조정)\n",
    "client.recreate_collection(\n",
    "    collection_name=\"feedback_vector_store\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=EMBEDDING_DIM, \n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(\"✅ feedback_vector_store 컬렉션 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6da980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d2905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinhy\\AppData\\Local\\Temp\\ipykernel_15148\\3498821153.py:6: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  vector_store = Qdrant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Qdrant에 벡터 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"description_vector_store\",\n",
    "    embeddings=embedding_model\n",
    ")\n",
    "\n",
    "vector_store.add_documents(split_docs_1)\n",
    "\n",
    "print(f\"✅ Qdrant에 벡터 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_model.embed_query(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f47e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Qdrant에 벡터 저장 완료\n"
     ]
    }
   ],
   "source": [
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"feedback_vector_store\",\n",
    "    embeddings=embedding_model\n",
    ")\n",
    "\n",
    "vector_store.add_documents(split_docs_2)\n",
    "\n",
    "print(f\"✅ Qdrant에 벡터 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "075236e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_name: 그랜저, 그랜저 | description: This car features a sleek estate body type with a balanced, elongated proportion. The smooth, aerodynamic surface enhances its modern look. Subtle lighting accents are integrated into the design, with a minimalist LED strip at the rear. The grill is narrow and\n",
      "{'description_keywords': ['sleek', 'modern', 'aerodynamic', 'dynamic'], 'url': 'car_images_all/3_1_그랜저.png', '_id': '008e453c-840b-45d0-add0-7446ff80a11e', '_collection_name': 'description_vector_store'}\n",
      "car_name: 투싼, 투싼 | description: This car features a modern SUV body type with sleek, balanced proportions. The surface has sharp, angular lines and smooth curves, creating a dynamic look. The lighting includes narrow, LED accents that enhance its contemporary feel. The grill is narrow and\n",
      "{'description_keywords': ['sleek', 'modern', 'dynamic'], 'url': 'car_images_all/4_6_투싼.png', '_id': '32cd2b06-4965-40fe-84c0-50d33cb29222', '_collection_name': 'description_vector_store'}\n",
      "car_name: 코나, 코나 | description: This car features a modern SUV body type with sleek, balanced proportions. The surface has sharp, angular lines and smooth curves, creating a dynamic appearance. The lighting includes narrow, contemporary LED strips. The grill is minimalist and integrated, enhancing\n",
      "{'description_keywords': ['sleek', 'modern', 'dynamic'], 'url': 'car_images_all/4_1_코나.png', '_id': '008bc30e-6be2-4e8d-8a39-099722c32ace', '_collection_name': 'description_vector_store'}\n",
      "car_name: 아이오닉 9, 아이오닉 9 | description: This car features a modern SUV body type with a sleek, elongated proportions. The surface is smooth with subtle curves, enhancing aerodynamics. The lighting appears integrated and streamlined, likely LED for a contemporary look. The grill is narrow and\n",
      "{'description_keywords': ['sleek', 'modern', 'dynamic'], 'url': 'car_images_all/1_4_아이오닉_9.png', '_id': '5e173ceb-c02b-4132-bae2-d1cd89f473c9', '_collection_name': 'description_vector_store'}\n",
      "car_name: 아반떼, 아반떼 | description: This car features a sleek sedan body type with a balanced and aerodynamic proportion. The surface is smooth with subtle curves and creases, enhancing its dynamic appearance. The lighting includes sharp, angular LED headlights and taillights that add a modern touch.\n",
      "{'description_keywords': ['sleek', 'modern', 'aerodynamic', 'sedan', 'dynamic'], 'url': 'car_images_all/3_3_아반떼.png', '_id': '1031883c-e9ac-4e7e-90ba-1d36580fa3dc', '_collection_name': 'description_vector_store'}\n"
     ]
    }
   ],
   "source": [
    "# 문서 내용 확인\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(host=\"3.35.81.92\", port=6333)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"description_vector_store\",\n",
    "    embeddings=embedding_model\n",
    ")\n",
    "\n",
    "# 전체 문서 일부만 확인 (최대 5개)\n",
    "docs = vector_store.similarity_search(\"아무 쿼리\", k=5)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "737fd681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car_images_all/3_1_그랜저.png'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata.get(\"url\")\n",
    "# type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7292fb33",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VectorStore.search() missing 2 required positional arguments: 'query' and 'search_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m search_result = \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription_vector_store\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# top 1\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m search_result\n",
      "\u001b[31mTypeError\u001b[39m: VectorStore.search() missing 2 required positional arguments: 'query' and 'search_type'"
     ]
    }
   ],
   "source": [
    "search_result = vector_store.search(\n",
    "    collection_name=\"description_vector_store\",\n",
    "    query_vector=embedding_model,\n",
    "    limit=1,  # top 1\n",
    "    with_payload=True\n",
    "    )\n",
    "search_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
