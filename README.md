# Image_to_text: InternVL3-8B-hf modelë¡œ car_image description ì¶”ì¶œ

##  í™œìš© ëª¨ë¸: InternVL3-8B-hf
: Huggingface Transformers í˜¸í™˜ë²„ì „ ([OpenGVLab/InternVL3-8B-hf Â· Hugging Face](https://huggingface.co/OpenGVLab/InternVL3-8B-hf?utm_source=chatgpt.com#usage-example))

- Vision Encoder (e.g. EVA-CLIP, ViT, Swin)
- Projector (image features â†’ text embedding space)
- LLM backbone (Qwen, LLaMA, Baichuan ë“±)
<img width="500" alt="image" src="https://github.com/user-attachments/assets/25397f71-3470-4ce3-b168-3fa393675e81" />

ğŸ’¡InternVL3ì˜ Backbone êµ¬ì¡°ë¥¼ í•œêµ­ì–´ ëª¨ë¸ë¡œ ë°”ê¿”ì•¼ í•˜ë‚˜...?<br>
backbone LLMì„ êµì²´í•˜ë ¤ë©´:<br>
1ï¸âƒ£ LLM input embedding dimê³¼ Vision Projector output dimì´ ì¼ì¹˜í•´ì•¼ í•¨<br>
2ï¸âƒ£ positional embedding, attention mask ê°™ì€ êµ¬ì¡°ê°€ í˜¸í™˜ë¼ì•¼ í•¨<br>
3ï¸âƒ£ tokenizer, special tokens ì²˜ë¦¬ë„ ë§ì¶°ì•¼ í•¨<br>

â†’ Qwenì„ í•œêµ­ì–´ ëª¨ë¸ë¡œ ë°”ê¿”ë³´ë ¤ê³  í–ˆëŠ”ë°, ê·¸ê±°ë³´ë‹¤ ì°¨ë¼ë¦¬ í•œêµ­ì–´ë¡œ ì¶”ê°€ì ì¸ finetuningì„ í•˜ê±°ë‚˜, outputê°’ì„ ì˜ì–´ë¡œ ë‚˜ì˜¤ê²Œ promptë¥¼ ì£¼ê³ ì í•¨.

### 1. InternVL3 fine-tuning ë°ì´í„° ì¤€ë¹„ <br>
: JSON íŒŒì¼(web_crawlingìœ¼ë¡œ ì´ë¦„,ì¢…ë¥˜) + ì´ë¯¸ì§€ íŒŒì¼ ë³„ë„ directoryë¡œ ì €ì¥

| ë°ì´í„° ìœ í˜• | ì˜ˆì‹œ í¬ë§· |
| --- | --- |
| ê²½ë¡œ ê¸°ë°˜ ë°ì´í„° | images/elantra.png + í…ìŠ¤íŠ¸ JSON/JSONLë¡œ ì—°ê²° |
| ë°”ì´ë„ˆë¦¬ ì§ì ‘ | webdataset (tarë¡œ ì´ë¯¸ì§€+ì£¼ì„ ì••ì¶•) |
| huggingface datasets | Dataset.from_json / from_dict |

â© JSON/JSONL í˜•ì‹, but, ì´ë¯¸ì§€ì˜ ê²½ìš° 

- binaryë¡œ ì§ì ‘ ë„£ëŠ” ê²Œ ì•„ë‹ˆë¼,
- ê²½ë¡œë¡œ ë„£ê³ , í•™ìŠµ ì½”ë“œì—ì„œ `PIL.Image.open(path)` ì‹ìœ¼ë¡œ ë¡œë“œ

### **2. GPU í™˜ê²½ ì„¤ì •(with RunPod)**


ğŸ’¡multimodal modelì€ colab ë¬´ë£Œ ë²„ì „ì—ì„œëŠ” ì•ˆ ëŒì•„ê°

â†’ Runpod ì‚¬ìš©í•´ì•¼ë¨! (ê·¸ì¤‘ì—ì„œë„  OOM(out of memory)ì´ ì•ˆë˜ëŠ” ì• ë“¤ë¡œ ê³¨ë¼ì„œ ì˜ ì¨ì•¼í•¨)

```bash
OutOfMemoryError: CUDA out of memory. 
Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 31.37 GiB of which 32.69 MiB is free. 
Including non-PyTorch memory, this process has 31.33 GiB memory in use. Of the allocated memory 30.57 GiB i
s allocated by PyTorch, and 185.26 MiB is reserved by PyTorch but unallocated. 
If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:
id fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```

| GPU | VRAM | ì§€ì› íƒ€ì… | ì í•©í•œ ìš©ë„ |
| --- | --- | --- | --- |
| **A6000** | 48GB | float16 | âœ… ì•ˆì •ì  + ê°€ì„±ë¹„ ì¢‹ìŒ â€“ ì¼ë°˜ ê°œë°œìš© ì¶”ì²œ |
| **A100 80GB** | 80GB | float16, bfloat16 | âœ… ì†ë„ì™€ ë©”ëª¨ë¦¬ ìµœê°• â€“ í”„ë¡œë•ì…˜/ë°°ì¹˜ì²˜ë¦¬ ì‹œ ì¶”ì²œ |
| **H100 80GB** | 80GB+ | float16, bfloat16 | âœ… ìµœê³ ì„±ëŠ¥ â€“ ë…¼ë¬¸, ê±°ëŒ€ ì‹¤í—˜ìš© â†’ ë¹„ìš© ê³ ë ¤ í•„ìˆ˜ |

<img width="1826" height="326" alt="image" src="https://github.com/user-attachments/assets/ac2a03c3-0a06-4637-be37-fd5c372da95f" />


â†’ í˜„ì¬ ë°ì´í„°ì…‹ìœ¼ë¡œëŠ” A6000ìœ¼ë¡œë„ ì¶©ë¶„í•¨ !!

### 3. hugging face `model card`ì—ì„œ usage example ê¼­ í™•ì¸!!

InternVL3 ëª¨ë¸ì´ ì‚¬ìš©í•˜ëŠ” message í˜•ì‹ ê°™ì€ê²Œ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆê¹, hugging face í™ˆí˜ì´ì§€ì— ë“¤ì–´ê°€ì„œ ê¼­ model cardì—ì„œ usage exampleë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤!! (ë§ˆìŒëŒ€ë¡œ ë„£ìœ¼ë©´ ì—ëŸ¬ ë°œìƒí•¨â€¦.)

<img width="700" alt="image" src="https://github.com/user-attachments/assets/0a19036f-92cc-48d8-a650-ef2be213d579" />

### 4. í•™ìŠµì‹œí‚¬ ë•Œ promptì˜ ì¤‘ìš”ì„±

ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì¤‘ìš”í•œê±´ ìë™ì°¨ ë””ìì´ë„ˆì—ê²Œ í•„ìš”í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ë“¤ì„ ë§Œë“¤ì–´ë‚´ì•¼í•¨.

ì´ˆê¸° í”„ë¡¬í”„íŠ¸(ì˜ë¬¸- backboneì´ Qwenëª¨ë¸ì´ë¼ì„œ ì˜ë¬¸ ì‘ì„±)

```python
"As an automotive designer, describe this car's design in detail, "
"incl. body type, proportions, surface treatments, lighting design, "
"grill pattern, wheel design, color palette, and any unique or futuristic elements."
```

â†’ ìì„¸í•´ì„œ ì¢‹ê¸´ í•œë° ë‚˜ì¤‘ì— text_to_image ëª¨ë¸ì— ë„£ì„ë•Œ token ì œí•œ ìˆ˜ ê±¸ë¦¼

**ğŸ’¥ Stable Diffusionì—ì„œì˜ í…ìŠ¤íŠ¸ token ì²˜ë¦¬ ë°©ì‹**

âœ… Stable Diffusion (íŠ¹íˆ v1.x, v2.x, SDXL ë“±)ì€

CLIP (OpenAI, Hugging Face ë“±ì—ì„œ ì œê³µ) tokenizerë¡œ í…ìŠ¤íŠ¸ë¥¼ encodingí•©ë‹ˆë‹¤.

- ë³´í†µ **BPE (Byte Pair Encoding) tokenizer** ê¸°ë°˜
- max length ì œí•œ ìˆìŒ

ìµœì¢… í”„ë¡¬í”„íŠ¸

```python
prompt = (
    "Describe this car's design briefly and precisely: body type, proportions, surface, lighting, grill, wheels, color, unique or futuristic elements."
)

```

### 5. ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•´ ì‚¬ìš©í•œ ì „ëµ

1ï¸âƒ£ float16 ì‚¬ìš© (quantization ì–‘ìí™”)

: ëª¨ë¸ê³¼ ë°ì´í„°ì˜ ìˆ«ì í‘œí˜„ì„ 32ë¹„íŠ¸(float32) â†’ 16ë¹„íŠ¸(float16)ë¡œ ì¤„ì—¬ ì—°ì‚°

- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•½ **ì ˆë°˜**ìœ¼ë¡œ ì¤„ì–´ë“¦.
- ì—°ì‚° ì†ë„ **í–¥ìƒ** (íŠ¹íˆ A100, H100 ê°™ì€ ìµœì‹  GPUì—ì„œ íš¨ê³¼ì ).
- large language model (LLM) & multimodal modelì—ì„œ ê±°ì˜ í•„ìˆ˜ ìµœì í™”.

```python
model = AutoModelForImageTextToText.from_pretrained(
    'model_name',
    device_map='cuda',
    torch_dtype=torch.float16  # âœ… float16ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
).to('cuda')

inputs = processor(...).to('cuda', dtype=torch.float16)  # inputsë„ ë§ì¶°ì¤Œ
```

2ï¸âƒ£ ì¶”ë¡ í• ë•Œ no_grad ì‚¬ìš© (gradient ê³„ì‚° ë¹„í™œì„±í™”)

: ì¶”ë¡ (inference)ì—ì„œ gradient ê³„ì‚°ì„ êº¼ì„œ backward íŒ¨ìŠ¤ ë©”ëª¨ë¦¬/ì—°ì‚° ì œê±°.

```python
with torch.no_grad():
    output = model.generate(**inputs, max_new_tokens=300)  # âœ… gradient ê³„ì‚° ì•ˆ í•¨
```

3ï¸âƒ£ loopë§ˆë‹¤ ë©”ëª¨ë¦¬ ì²­ì†Œ (ìºì‹œ ì •ë¦¬)

: ê° ì´ë¯¸ì§€/ë°°ì¹˜ ì²˜ë¦¬ í›„ ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±°, GPU ìºì‹œ ë¹„ìš°ê¸°, Python garbage collection ì‹¤í–‰.

- GPU ë©”ëª¨ë¦¬ **ëˆ„ì  ë°©ì§€** â†’ Out Of Memory (OOM) ì—ëŸ¬ ë°©ì–´.
- íŠ¹íˆ **ëŒ€ê·œëª¨ ì´ë¯¸ì§€/ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ loop**ì—ì„œ ë©”ëª¨ë¦¬ ë¦­ ë°©ì§€.
